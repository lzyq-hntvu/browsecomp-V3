# æ–¹æ¡ˆAè¯¦ç»†è®¾è®¡æ–‡æ¡£: LLMåˆæˆç”Ÿæˆæ–¹æ¡ˆ

**æ—¥æœŸ**: 2026-02-04  
**ç‰ˆæœ¬**: v1.0  
**çŠ¶æ€**: è®¾è®¡é˜¶æ®µ

---

## ğŸ“‹ ç›®å½•

1. [æ–¹æ¡ˆæ¦‚è¿°](#æ–¹æ¡ˆæ¦‚è¿°)
2. [æ ¸å¿ƒæœºåˆ¶](#æ ¸å¿ƒæœºåˆ¶)
3. [é£é™©åˆ†æä¸è§£å†³æ–¹æ¡ˆ](#é£é™©åˆ†æä¸è§£å†³æ–¹æ¡ˆ)
4. [å®Œæ•´æ¶æ„è®¾è®¡](#å®Œæ•´æ¶æ„è®¾è®¡)
5. [ä»£ç å®ç°æ¡†æ¶](#ä»£ç å®ç°æ¡†æ¶)
6. [å®æ–½è®¡åˆ’](#å®æ–½è®¡åˆ’)
7. [æˆæœ¬æ•ˆç›Šåˆ†æ](#æˆæœ¬æ•ˆç›Šåˆ†æ)

---

## æ–¹æ¡ˆæ¦‚è¿°

### æ ¸å¿ƒæ€æƒ³

**æ”¾å¼ƒä»çŸ¥è¯†å›¾è°±é‡‡æ ·çœŸå®æ•°æ®,æ”¹ç”¨LLMæ‰¹é‡ç”Ÿæˆ"è™šæ‹Ÿå­¦è€…æ¡£æ¡ˆ"**

```
ä¼ ç»ŸV3æ–¹æ¡ˆ:
  QandA KG (çœŸå®ä½†ä¸å®Œæ•´,46%çº¦æŸå¤±è´¥) â†’ é‡‡æ · â†’ ç”Ÿæˆé—®é¢˜

æ–¹æ¡ˆA (æ”¹è¿›ç‰ˆ):
  LLMç”Ÿæˆè™šæ‹Ÿæ¡£æ¡ˆ â†’ ç¡¬ç¼–ç è§„åˆ™éªŒè¯ â†’ é‡‡æ ·ç»„åˆ â†’ ç”Ÿæˆé—®é¢˜
```

### å…³é”®ä¼˜åŠ¿

| æŒ‡æ ‡ | V3(KGæ–¹æ¡ˆ) | æ–¹æ¡ˆA(LLMåˆæˆ) | æå‡ |
|------|-----------|---------------|------|
| **çº¦æŸå¯ç”¨ç‡** | 26.7% (8/30) | 100% (30/30) | +274% |
| **å¹³å‡çº¦æŸæ•°** | 1.2ä¸ª/é—®é¢˜ | 3-5ä¸ª/é—®é¢˜ | +250% |
| **ç”ŸæˆæˆåŠŸç‡** | 14% | 70%+ | +400% |
| **å•é¢˜æˆæœ¬** | N/A (å—é™) | $0.5-1 | èŠ‚çœ90-95% |
| **ç”Ÿæˆé€Ÿåº¦** | 33-57 Q/ç§’ | 100+ Q/ç§’ | +200% |

### å…³é”®é£é™©

1. **å¤šå®ä½“äº¤å‰çº¦æŸé€»è¾‘çŸ›ç›¾** - å¦‚åšå£«æ¯•ä¸šå¹´ä»½ä¸é¦–ç¯‡è®ºæ–‡å‘è¡¨æ—¶é—´å†²çª
2. **LLMç­”æ¡ˆå”¯ä¸€æ€§ä¸ç¨³å®š** - åŒä¸€é—®é¢˜å¤šæ¬¡é‡‡æ ·å¾—åˆ°ä¸åŒç­”æ¡ˆ
3. **"è¡¨é¢åˆç†ä½†æ·±å±‚è’è°¬"** - æ—¶é—´é”™ä½ã€å®ä½“åå†²çªç­‰

---

## æ ¸å¿ƒæœºåˆ¶

### æœºåˆ¶1: è™šæ‹Ÿå­¦è€…æ¡£æ¡ˆç”Ÿæˆ

**æ ¸å¿ƒæ•°æ®ç»“æ„**:

```python
@dataclass
class ScholarProfile:
    """è™šæ‹Ÿå­¦è€…æ¡£æ¡ˆ"""
    # åŸºæœ¬ä¿¡æ¯
    scholar_id: str          # å”¯ä¸€ID: "scholar_001"
    name: str                 # LLMç”Ÿæˆçš„å§“å: "ææ˜è½©"
    birth_year: int           # å‡ºç”Ÿå¹´ä»½: 1990
    
    # æ•™è‚²èƒŒæ™¯
    bachelor_uni: str         # æœ¬ç§‘é™¢æ ¡: "æ¸…åå¤§å­¦"
    bachelor_year: int        # æœ¬ç§‘æ¯•ä¸š: 2012
    bachelor_major: str       # æœ¬ç§‘ä¸“ä¸š: "è®¡ç®—æœºç§‘å­¦"
    
    phd_uni: str             # åšå£«é™¢æ ¡: "MIT"
    phd_year: int            # åšå£«æ¯•ä¸š: 2017
    phd_major: str           # åšå£«ä¸“ä¸š: "äººå·¥æ™ºèƒ½"
    advisor: str             # å¯¼å¸ˆå§“å: "å¼ ä¼Ÿæ•™æˆ"
    
    # èŒä¸šå‘å±•
    current_affiliation: str # å½“å‰æœºæ„: "Stanford University"
    current_position: str    # å½“å‰èŒä½: "åŠ©ç†æ•™æˆ"
    join_year: int           # å…¥èŒå¹´ä»½: 2018
    
    # å­¦æœ¯äº§å‡º
    papers: List[Paper]      # å‘è¡¨è®ºæ–‡åˆ—è¡¨
    total_citations: int     # æ€»å¼•ç”¨æ•°
    h_index: int             # hæŒ‡æ•°
    
    # å­¦æœ¯è£èª‰
    awards: List[str]        # è·å¥–åˆ—è¡¨
    
    def validate_timeline(self) -> Tuple[bool, List[str]]:
        """éªŒè¯æ—¶é—´çº¿ä¸€è‡´æ€§"""
        errors = []
        
        # è§„åˆ™1: æœ¬ç§‘æ¯•ä¸šå¹´é¾„ >= 18
        if self.bachelor_year - self.birth_year < 18:
            errors.append(f"æœ¬ç§‘æ¯•ä¸šè¿‡æ—©: {self.bachelor_year - self.birth_year}å²")
        
        # è§„åˆ™2: åšå£«å­¦ä¹ æ—¶é—´ >= 4å¹´
        if self.phd_year - self.bachelor_year < 4:
            errors.append(f"åšå£«å­¦ä¹ æ—¶é—´è¿‡çŸ­: {self.phd_year - self.bachelor_year}å¹´")
        
        # è§„åˆ™3: é¦–ç¯‡è®ºæ–‡ >= åšå£«æ¯•ä¸š + 1å¹´
        if self.papers:
            first_paper_year = min(p.year for p in self.papers)
            if first_paper_year < self.phd_year + 1:
                errors.append(f"é¦–ç¯‡è®ºæ–‡æ—©äºåšå£«æ¯•ä¸š: {first_paper_year} < {self.phd_year}")
        
        # è§„åˆ™4: å…¥èŒæ—¶é—´ >= åšå£«æ¯•ä¸š
        if self.join_year < self.phd_year:
            errors.append(f"å…¥èŒæ—©äºåšå£«æ¯•ä¸š: {self.join_year} < {self.phd_year}")
        
        # è§„åˆ™5: æ‰€æœ‰è®ºæ–‡å¹´ä»½ä¸æ™šäºä»Šå¹´
        current_year = 2024
        for paper in self.papers:
            if paper.year > current_year:
                errors.append(f"è®ºæ–‡å¹´ä»½è¶…å‡ºå½“å‰: {paper.year} > {current_year}")
        
        # è§„åˆ™6: å¼•ç”¨æ•°ä¸è®ºæ–‡æ•°çš„åˆç†æ€§
        if self.papers:
            avg_citations = self.total_citations / len(self.papers)
            if avg_citations > 1000:  # å•ç¯‡å¹³å‡å¼•ç”¨è¿‡é«˜
                errors.append(f"å¹³å‡å¼•ç”¨æ•°å¼‚å¸¸: {avg_citations:.0f}")
        
        return len(errors) == 0, errors

@dataclass
class Paper:
    """è™šæ‹Ÿè®ºæ–‡æ¡£æ¡ˆ"""
    paper_id: str            # å”¯ä¸€ID: "paper_001"
    title: str                # è®ºæ–‡æ ‡é¢˜ (LLMç”Ÿæˆ)
    year: int                 # å‘è¡¨å¹´ä»½
    venue: str               # ä¼šè®®/æœŸåˆŠå
    venue_type: str          # ç±»å‹: "conference" / "journal"
    
    # ä½œè€…ä¿¡æ¯
    authors: List[str]       # ä½œè€…å§“ååˆ—è¡¨ (å¼•ç”¨ScholarProfile.name)
    author_affiliations: Dict[str, str]  # ä½œè€…-æœºæ„æ˜ å°„
    
    # è®ºæ–‡å±æ€§
    citation_count: int      # å¼•ç”¨æ•°
    section_count: int       # ç« èŠ‚æ•°
    page_count: int          # é¡µæ•°
    keywords: List[str]      # å…³é”®è¯
    
    # æ‰©å±•å±æ€§ (æ”¯æŒæ›´å¤šçº¦æŸ)
    abstract: str            # æ‘˜è¦ (å¯é€‰)
    references_count: int    # å‚è€ƒæ–‡çŒ®æ•°
    
    def validate_consistency(self) -> Tuple[bool, List[str]]:
        """éªŒè¯è®ºæ–‡å†…éƒ¨ä¸€è‡´æ€§"""
        errors = []
        
        # è§„åˆ™1: è‡³å°‘1ä¸ªä½œè€…
        if len(self.authors) == 0:
            errors.append("è®ºæ–‡å¿…é¡»æœ‰ä½œè€…")
        
        # è§„åˆ™2: å¼•ç”¨æ•°ä¸èƒ½ä¸ºè´Ÿ
        if self.citation_count < 0:
            errors.append(f"å¼•ç”¨æ•°ä¸ºè´Ÿ: {self.citation_count}")
        
        # è§„åˆ™3: ç« èŠ‚æ•°åˆç†èŒƒå›´
        if not (3 <= self.section_count <= 12):
            errors.append(f"ç« èŠ‚æ•°ä¸åˆç†: {self.section_count}")
        
        # è§„åˆ™4: é¡µæ•°åˆç†èŒƒå›´
        if not (4 <= self.page_count <= 50):
            errors.append(f"é¡µæ•°ä¸åˆç†: {self.page_count}")
        
        return len(errors) == 0, errors
```

**ç”Ÿæˆæµç¨‹**:

```python
class ScholarProfileGenerator:
    """è™šæ‹Ÿå­¦è€…æ¡£æ¡ˆç”Ÿæˆå™¨"""
    
    def __init__(self, llm_client):
        self.llm = llm_client
    
    def generate_profiles(self, count: int = 1000) -> List[ScholarProfile]:
        """æ‰¹é‡ç”Ÿæˆå­¦è€…æ¡£æ¡ˆ"""
        profiles = []
        
        for i in range(count):
            max_retries = 3
            for attempt in range(max_retries):
                # ç”Ÿæˆæ¡£æ¡ˆ
                profile = self._generate_single_profile(scholar_id=f"scholar_{i:04d}")
                
                # éªŒè¯æ—¶é—´çº¿
                is_valid, errors = profile.validate_timeline()
                
                if is_valid:
                    profiles.append(profile)
                    break
                else:
                    logger.warning(f"Profile {i} invalid (attempt {attempt+1}): {errors}")
            
            if i % 100 == 0:
                logger.info(f"Generated {i}/{count} profiles")
        
        logger.info(f"Successfully generated {len(profiles)}/{count} valid profiles")
        return profiles
    
    def _generate_single_profile(self, scholar_id: str) -> ScholarProfile:
        """ç”Ÿæˆå•ä¸ªå­¦è€…æ¡£æ¡ˆ"""
        
        prompt = """
        Generate a realistic but fictional academic scholar profile in JSON format:
        
        Requirements:
        1. Name: Plausible Chinese/English name (not too common, e.g., avoid "Zhang Wei")
        2. Timeline: Birth year 1985-1995, bachelor graduation at 22, PhD 4-6 years later
        3. Institutions: Real top universities (MIT, Stanford, Tsinghua, etc.)
        4. Papers: 3-8 papers, published 1-10 years after PhD graduation
        5. All dates must be logically consistent
        
        Output JSON schema:
        {
            "name": "ææ˜è½©",
            "birth_year": 1990,
            "bachelor_uni": "æ¸…åå¤§å­¦",
            "bachelor_year": 2012,
            "phd_uni": "MIT",
            "phd_year": 2017,
            "advisor": "John Doe",
            "current_affiliation": "Stanford University",
            "join_year": 2018,
            "papers": [
                {
                    "title": "Attention Mechanisms for Multi-hop Reasoning",
                    "year": 2019,
                    "venue": "EMNLP",
                    "citation_count": 150,
                    "section_count": 6
                }
            ]
        }
        """
        
        # LLMç”Ÿæˆ
        response = self.llm.generate(prompt, temperature=0.7, response_format="json")
        
        # è§£æJSON
        data = json.loads(response)
        
        # æ„å»ºScholarProfileå¯¹è±¡
        papers = [Paper(**p, paper_id=f"{scholar_id}_p{i}") for i, p in enumerate(data["papers"])]
        
        profile = ScholarProfile(
            scholar_id=scholar_id,
            name=data["name"],
            birth_year=data["birth_year"],
            bachelor_uni=data["bachelor_uni"],
            bachelor_year=data["bachelor_year"],
            phd_uni=data["phd_uni"],
            phd_year=data["phd_year"],
            advisor=data["advisor"],
            current_affiliation=data["current_affiliation"],
            join_year=data["join_year"],
            papers=papers,
            total_citations=sum(p.citation_count for p in papers),
            h_index=calculate_h_index(papers)
        )
        
        return profile
```

### æœºåˆ¶2: çº¦æŸå…¼å®¹æ€§éªŒè¯

**æ ¸å¿ƒé—®é¢˜**: å¤šä¸ªçº¦æŸç»„åˆæ—¶å¯èƒ½äº§ç”Ÿé€»è¾‘çŸ›ç›¾

**è§£å†³æ–¹æ¡ˆ**: åˆ†å±‚çº¦æŸéªŒè¯å™¨

```python
class ConstraintValidator:
    """çº¦æŸå…¼å®¹æ€§éªŒè¯å™¨"""
    
    def __init__(self):
        # å®šä¹‰çº¦æŸä¹‹é—´çš„ä¾èµ–å…³ç³»å’Œè§„åˆ™
        self.constraint_rules = {
            # (çº¦æŸ1, çº¦æŸ2): éªŒè¯å‡½æ•°
            ("phd_year", "first_paper_year"): lambda phd, paper: paper >= phd + 1,
            ("birth_year", "bachelor_year"): lambda birth, bachelor: bachelor - birth >= 18,
            ("bachelor_year", "phd_year"): lambda bachelor, phd: phd - bachelor >= 4,
            ("phd_year", "join_year"): lambda phd, join: join >= phd,
            
            # å¤šå®ä½“çº¦æŸ
            ("coauthor_history_year", "phd_year_author1"): lambda coauthor, phd: coauthor >= phd - 4,
            ("coauthor_history_year", "phd_year_author2"): lambda coauthor, phd: coauthor >= phd - 4,
        }
        
        # çº¦æŸä¼˜å…ˆçº§ (é«˜ä¼˜å…ˆçº§çº¦æŸä¸ä¼šè¢«è°ƒæ•´)
        self.priority_order = [
            "birth_year",       # æœ€é«˜ä¼˜å…ˆçº§
            "bachelor_year",
            "phd_year",
            "join_year",
            "paper_year",
            "coauthor_year",    # æœ€ä½ä¼˜å…ˆçº§
        ]
    
    def check_compatibility(self, constraints: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """æ£€æŸ¥çº¦æŸç»„åˆæ˜¯å¦å…¼å®¹"""
        errors = []
        
        # æ£€æŸ¥æ‰€æœ‰çº¦æŸå¯¹
        for (c1_name, c2_name), rule in self.constraint_rules.items():
            if c1_name in constraints and c2_name in constraints:
                v1 = constraints[c1_name]
                v2 = constraints[c2_name]
                
                if not rule(v1, v2):
                    errors.append(f"çº¦æŸå†²çª: {c1_name}={v1}, {c2_name}={v2}")
        
        return len(errors) == 0, errors
    
    def auto_adjust_constraints(self, constraints: Dict[str, Any]) -> Dict[str, Any]:
        """è‡ªåŠ¨è°ƒæ•´çº¦æŸå€¼ä»¥æ¶ˆé™¤çŸ›ç›¾"""
        adjusted = constraints.copy()
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        sorted_keys = sorted(adjusted.keys(), 
                           key=lambda k: self.priority_order.index(k) if k in self.priority_order else 999)
        
        # ä»é«˜ä¼˜å…ˆçº§åˆ°ä½ä¼˜å…ˆçº§ä¾æ¬¡éªŒè¯å’Œè°ƒæ•´
        for i, current_key in enumerate(sorted_keys):
            # æ£€æŸ¥ä¸å·²ç¡®å®šçº¦æŸçš„å…¼å®¹æ€§
            partial_constraints = {k: adjusted[k] for k in sorted_keys[:i+1]}
            is_compatible, errors = self.check_compatibility(partial_constraints)
            
            if not is_compatible:
                # è°ƒæ•´å½“å‰çº¦æŸå€¼
                new_value = self._suggest_compatible_value(current_key, adjusted, sorted_keys[:i])
                adjusted[current_key] = new_value
                logger.warning(f"è°ƒæ•´çº¦æŸ {current_key}: {constraints[current_key]} -> {new_value}")
        
        return adjusted
    
    def _suggest_compatible_value(self, key: str, constraints: Dict, fixed_keys: List[str]) -> Any:
        """ä¸ºçº¦æŸå»ºè®®å…¼å®¹çš„å€¼"""
        
        # åŸºäºå·²å›ºå®šçš„çº¦æŸæ¨æ–­åˆç†å€¼
        if key == "paper_year" and "phd_year" in constraints:
            return constraints["phd_year"] + random.randint(1, 5)
        
        elif key == "join_year" and "phd_year" in constraints:
            return constraints["phd_year"] + random.randint(0, 2)
        
        elif key == "coauthor_year":
            if "phd_year" in constraints:
                return constraints["phd_year"] + random.randint(1, 8)
        
        # é»˜è®¤: è¿”å›åŸå€¼
        return constraints[key]
```

### æœºåˆ¶3: ç­”æ¡ˆå”¯ä¸€æ€§ä¿è¯

**æ ¸å¿ƒé—®é¢˜**: LLMç”Ÿæˆçš„ç­”æ¡ˆä¸ç¨³å®š,åŒä¸€é—®é¢˜å¤šæ¬¡é‡‡æ ·å¾—åˆ°ä¸åŒç­”æ¡ˆ

**è§£å†³æ–¹æ¡ˆ**: å››å±‚å”¯ä¸€æ€§ä¿è¯æœºåˆ¶

```python
class UniquenessGuarantee:
    """ç­”æ¡ˆå”¯ä¸€æ€§ä¿è¯æœºåˆ¶"""
    
    def __init__(self, llm_client):
        self.llm = llm_client
    
    def ensure_uniqueness(self, 
                         template: str, 
                         constraints: Dict[str, Any],
                         profiles: List[ScholarProfile]) -> Optional[Tuple[str, str]]:
        """
        ç»¼åˆä½¿ç”¨4ç§æ–¹æ³•ä¿è¯ç­”æ¡ˆå”¯ä¸€æ€§
        
        Returns:
            (question, answer) if successful, None if failed
        """
        
        # æ–¹æ³•1: ç¼©å°ç­”æ¡ˆç©ºé—´ (æ·»åŠ æ›´å¤šçº¦æŸ)
        enhanced_constraints = self._add_specificity_constraints(constraints, profiles)
        
        # æ–¹æ³•2: ç»“æ„åŒ–ç”Ÿæˆæç¤º
        structured_prompt = self._build_structured_prompt(template, enhanced_constraints)
        
        # æ–¹æ³•3: æ˜¾å¼è¦æ±‚ç­”æ¡ˆå”¯ä¸€æ€§
        prompt_with_requirement = self._add_uniqueness_requirement(structured_prompt)
        
        # æ–¹æ³•4: ç”Ÿæˆå¹¶éªŒè¯ä¸€è‡´æ€§
        for attempt in range(3):
            # ç”ŸæˆQAå¯¹
            qa_pair = self.llm.generate(prompt_with_requirement, temperature=0.3)
            
            # å¤šæ¬¡é‡‡æ ·éªŒè¯ç­”æ¡ˆä¸€è‡´æ€§
            is_unique, consistency_rate = self._check_consistency(
                qa_pair["question"], 
                expected_answer=qa_pair["answer"],
                n_samples=5,
                threshold=0.8
            )
            
            if is_unique:
                logger.info(f"ç­”æ¡ˆå”¯ä¸€æ€§éªŒè¯é€šè¿‡ (ä¸€è‡´æ€§: {consistency_rate:.2%})")
                return qa_pair["question"], qa_pair["answer"]
            else:
                logger.warning(f"ç­”æ¡ˆå”¯ä¸€æ€§ä¸è¶³ (attempt {attempt+1}, ä¸€è‡´æ€§: {consistency_rate:.2%})")
        
        logger.error("3æ¬¡å°è¯•åä»æ— æ³•ä¿è¯ç­”æ¡ˆå”¯ä¸€æ€§")
        return None
    
    def _add_specificity_constraints(self, 
                                    constraints: Dict[str, Any],
                                    profiles: List[ScholarProfile]) -> Dict[str, Any]:
        """
        æ–¹æ³•1: æ·»åŠ æ›´å…·ä½“çš„çº¦æŸä»¥ç¼©å°ç­”æ¡ˆç©ºé—´
        
        ç­–ç•¥: å°†æ³›åŒ–çº¦æŸæ›¿æ¢ä¸ºå…·ä½“å®ä½“çº¦æŸ
        ä¾‹å¦‚: "æœ¬ç§‘æ¯•ä¸šäºMIT" -> "ä½œè€…ææ˜è½©,æœ¬ç§‘æ¯•ä¸šäºMIT,åšå£«æ¯•ä¸šäºStanford"
        """
        enhanced = constraints.copy()
        
        # å¦‚æœçº¦æŸä¸­æ²¡æœ‰å…·ä½“äººå,éšæœºé€‰æ‹©ä¸€ä¸ªå­¦è€…å¹¶æ·»åŠ å…¶è¯¦ç»†ä¿¡æ¯
        if "author_name" not in enhanced:
            scholar = random.choice(profiles)
            enhanced.update({
                "author_name": scholar.name,
                "author_bachelor_uni": scholar.bachelor_uni,
                "author_phd_uni": scholar.phd_uni,
                "author_current_affiliation": scholar.current_affiliation
            })
        
        # å¦‚æœæœ‰è®ºæ–‡ç›¸å…³çº¦æŸ,é€‰æ‹©è¯¥å­¦è€…çš„ä¸€ç¯‡å…·ä½“è®ºæ–‡
        if "paper_year" in enhanced:
            scholar_name = enhanced["author_name"]
            scholar = next(s for s in profiles if s.name == scholar_name)
            
            # é€‰æ‹©ç¬¦åˆå¹´ä»½çº¦æŸçš„è®ºæ–‡
            matching_papers = [p for p in scholar.papers if p.year == enhanced["paper_year"]]
            if matching_papers:
                paper = random.choice(matching_papers)
                enhanced["paper_title"] = paper.title  # ç›´æ¥æŒ‡å®šç­”æ¡ˆ!
        
        return enhanced
    
    def _build_structured_prompt(self, template: str, constraints: Dict[str, Any]) -> str:
        """
        æ–¹æ³•2: æ„å»ºç»“æ„åŒ–ç”Ÿæˆæç¤º
        
        è¦æ±‚LLMè¾“å‡ºJSONæ ¼å¼,å‡å°‘æ­§ä¹‰
        """
        prompt = f"""
        Generate a question-answer pair based on the following template and constraints.
        
        Template: {template}
        Constraints: {json.dumps(constraints, ensure_ascii=False, indent=2)}
        
        Output in JSON format:
        {{
            "entities": {{
                "scholar": {{
                    "name": "ææ˜è½©",
                    "bachelor_uni": "æ¸…åå¤§å­¦",
                    "phd_uni": "MIT",
                    "current_affiliation": "Stanford University"
                }},
                "paper": {{
                    "title": "Attention Mechanisms for Multi-hop Reasoning",
                    "year": 2020,
                    "venue": "EMNLP",
                    "authors": ["ææ˜è½©", "John Smith"]
                }}
            }},
            "question": "2020å¹´å‘è¡¨åœ¨EMNLPçš„è®ºæ–‡ä¸­,ä½œè€…ææ˜è½©(æœ¬ç§‘æ¯•ä¸šäºæ¸…åå¤§å­¦,åšå£«æ¯•ä¸šäºMIT,ç°ä»»èŒäºStanford University)çš„è®ºæ–‡æ ‡é¢˜æ˜¯ä»€ä¹ˆ?",
            "answer": "Attention Mechanisms for Multi-hop Reasoning"
        }}
        
        IMPORTANT: The question must uniquely identify the answer through the constraints.
        """
        return prompt
    
    def _add_uniqueness_requirement(self, prompt: str) -> str:
        """
        æ–¹æ³•3: åœ¨æç¤ºä¸­æ˜¾å¼è¦æ±‚ç­”æ¡ˆå”¯ä¸€æ€§
        """
        uniqueness_instruction = """
        
        CRITICAL UNIQUENESS REQUIREMENTS:
        1. The answer must be SHORT and SPECIFIC (< 10 words)
        2. The question must include ENOUGH constraints to uniquely identify the answer
        3. If you were asked this question 5 times, you should give the SAME answer every time
        4. Avoid ambiguous wording that could lead to multiple valid answers
        5. Include specific entity names (not just "an author from MIT")
        """
        return prompt + uniqueness_instruction
    
    def _check_consistency(self, 
                          question: str, 
                          expected_answer: str,
                          n_samples: int = 5,
                          threshold: float = 0.8) -> Tuple[bool, float]:
        """
        æ–¹æ³•4: å¤šæ¬¡é‡‡æ ·éªŒè¯ç­”æ¡ˆä¸€è‡´æ€§
        
        Returns:
            (is_unique, consistency_rate)
        """
        answers = []
        
        for i in range(n_samples):
            # ä½æ¸©åº¦é‡‡æ ·,å¢åŠ ç¨³å®šæ€§
            answer = self.llm.generate(
                f"Question: {question}\nAnswer (short and specific):",
                temperature=0.2,
                max_tokens=50
            ).strip().lower()
            
            answers.append(answer)
        
        # ç»Ÿè®¡ä¸é¢„æœŸç­”æ¡ˆçš„åŒ¹é…åº¦
        expected_lower = expected_answer.strip().lower()
        matches = sum(1 for a in answers if self._is_answer_match(a, expected_lower))
        
        consistency_rate = matches / n_samples
        is_unique = consistency_rate >= threshold
        
        return is_unique, consistency_rate
    
    def _is_answer_match(self, answer: str, expected: str) -> bool:
        """åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦åŒ¹é… (å…è®¸è½»å¾®å·®å¼‚)"""
        # ç²¾ç¡®åŒ¹é…
        if answer == expected:
            return True
        
        # æ¨¡ç³ŠåŒ¹é… (ç¼–è¾‘è·ç¦»)
        from difflib import SequenceMatcher
        similarity = SequenceMatcher(None, answer, expected).ratio()
        return similarity >= 0.85
```

### æœºåˆ¶4: å¯éªŒè¯æ€§è®¾è®¡

**æ ¸å¿ƒé—®é¢˜**: åˆæˆæ•°æ®"è¡¨é¢åˆç†ä½†æ·±å±‚è’è°¬"

**è§£å†³æ–¹æ¡ˆ**: çœŸå®æœºæ„ + è™šæ„å­¦è€… + å¯éªŒè¯ç±»å‹

```python
class VerifiabilityDesign:
    """å¯éªŒè¯æ€§è®¾è®¡ç­–ç•¥"""
    
    # ç­–ç•¥1: ä½¿ç”¨çœŸå®çš„é¡¶å°–æœºæ„
    REAL_INSTITUTIONS = [
        # å›½å†…
        "æ¸…åå¤§å­¦", "åŒ—äº¬å¤§å­¦", "å¤æ—¦å¤§å­¦", "ä¸Šæµ·äº¤é€šå¤§å­¦", 
        "æµ™æ±Ÿå¤§å­¦", "å—äº¬å¤§å­¦", "ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦",
        
        # å›½é™…
        "MIT", "Stanford University", "Harvard University", 
        "UC Berkeley", "Carnegie Mellon University",
        "University of Cambridge", "University of Oxford",
    ]
    
    # ç­–ç•¥2: ä½¿ç”¨çœŸå®çš„é¡¶çº§ä¼šè®®/æœŸåˆŠ
    REAL_VENUES = {
        "conference": ["EMNLP", "ACL", "NAACL", "ICLR", "NeurIPS", "ICML", "AAAI"],
        "journal": ["Nature", "Science", "Cell", "PNAS", "TACL"]
    }
    
    def generate_plausible_name(self, name_type: str = "chinese") -> str:
        """
        ç”Ÿæˆåˆç†ä½†ä¸å¸¸è§çš„å§“å
        
        ç­–ç•¥: é¿å…è¶…å¸¸è§åå­— (å¦‚"å¼ ä¼Ÿ"),ä½¿ç”¨ä¸­ç­‰é¢‘ç‡çš„åå­—
        """
        if name_type == "chinese":
            # ä¸­ç­‰é¢‘ç‡çš„å§“æ°
            surnames = ["æ", "ç‹", "åˆ˜", "é™ˆ", "æ¨", "èµµ", "é»„", "å‘¨", "å´", "å¾"]
            # ä¸å¤ªå¸¸è§çš„åå­—
            given_names = ["æ˜è½©", "é›¨è±", "å­æ¶µ", "æ€è¿œ", "å®‡èˆª", "è¯—æ¶µ", "æ¢“è½©", "æ¬£æ€¡"]
            
            return random.choice(surnames) + random.choice(given_names)
        
        elif name_type == "english":
            first_names = ["Alex", "Jordan", "Taylor", "Morgan", "Casey", "Avery"]
            last_names = ["Chen", "Li", "Wang", "Zhang", "Liu", "Yang"]
            
            return f"{random.choice(first_names)} {random.choice(last_names)}"
    
    def add_fictional_disclaimer(self, question: str) -> str:
        """
        ç­–ç•¥3: åœ¨é—®é¢˜ä¸­æ·»åŠ è™šæ„å£°æ˜ (å¯é€‰)
        
        æ³¨æ„: è¿™ä¼šé™ä½é—®é¢˜çš„"çœŸå®æ„Ÿ",è°¨æ…ä½¿ç”¨
        """
        disclaimer = "[è™šæ„åœºæ™¯] "
        return disclaimer + question
    
    def validate_entity_plausibility(self, profile: ScholarProfile) -> Tuple[bool, List[str]]:
        """
        éªŒè¯å®ä½“çš„åˆç†æ€§
        """
        warnings = []
        
        # æ£€æŸ¥1: æœºæ„æ˜¯å¦çœŸå®
        if profile.bachelor_uni not in self.REAL_INSTITUTIONS:
            warnings.append(f"æœ¬ç§‘é™¢æ ¡ä¸åœ¨çœŸå®åˆ—è¡¨ä¸­: {profile.bachelor_uni}")
        
        if profile.phd_uni not in self.REAL_INSTITUTIONS:
            warnings.append(f"åšå£«é™¢æ ¡ä¸åœ¨çœŸå®åˆ—è¡¨ä¸­: {profile.phd_uni}")
        
        # æ£€æŸ¥2: è®ºæ–‡å‘è¡¨venueæ˜¯å¦çœŸå®
        for paper in profile.papers:
            all_venues = self.REAL_VENUES["conference"] + self.REAL_VENUES["journal"]
            if paper.venue not in all_venues:
                warnings.append(f"è®ºæ–‡venueä¸åœ¨çœŸå®åˆ—è¡¨ä¸­: {paper.venue}")
        
        # æ£€æŸ¥3: å§“åæ˜¯å¦è¿‡äºå¸¸è§
        common_names = ["å¼ ä¼Ÿ", "ç‹ä¼Ÿ", "æå¨œ", "Zhang Wei", "Li Wei"]
        if profile.name in common_names:
            warnings.append(f"å§“åè¿‡äºå¸¸è§,å¯èƒ½ä¸çœŸäººå†²çª: {profile.name}")
        
        return len(warnings) == 0, warnings
```

---

## é£é™©åˆ†æä¸è§£å†³æ–¹æ¡ˆ

### é£é™©çŸ©é˜µ

| é£é™© | ä¸¥é‡ç¨‹åº¦ | å‘ç”Ÿæ¦‚ç‡ | è§£å†³æ–¹æ¡ˆ | æ®‹ä½™é£é™© |
|------|---------|---------|---------|---------|
| **å¤šå®ä½“äº¤å‰çº¦æŸçŸ›ç›¾** | é«˜ | ä¸­ (40%) | çº¦æŸå…¼å®¹æ€§éªŒè¯å™¨ + è‡ªåŠ¨è°ƒæ•´ | ä½ (10%) |
| **ç­”æ¡ˆå”¯ä¸€æ€§ä¸ç¨³å®š** | é«˜ | é«˜ (60%) | 4å±‚å”¯ä¸€æ€§ä¿è¯æœºåˆ¶ | ä¸­ (20%) |
| **è¡¨é¢åˆç†ä½†æ·±å±‚è’è°¬** | ä¸­ | ä¸­ (30%) | çœŸå®æœºæ„ + è™šæ„å­¦è€…ç­–ç•¥ | ä½ (10%) |
| **LLMæˆæœ¬è¶…é¢„ç®—** | ä½ | ä½ (10%) | ä½¿ç”¨è½»é‡çº§æ¨¡å‹åˆç­› | æä½ (5%) |
| **ç”Ÿæˆè´¨é‡ä¸è¾¾æ ‡** | ä¸­ | ä¸­ (30%) | LLM-as-Verifier + äººå·¥æŠ½æ · | ä½ (10%) |

### è¯¦ç»†è§£å†³æ–¹æ¡ˆ

è§ä¸Šæ–‡[æ ¸å¿ƒæœºåˆ¶](#æ ¸å¿ƒæœºåˆ¶)éƒ¨åˆ†çš„è¯¦ç»†å®ç°ã€‚

---

## å®Œæ•´æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ–¹æ¡ˆA: LLMåˆæˆç”Ÿæˆç³»ç»Ÿ                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ1: è™šæ‹Ÿå­¦è€…æ¡£æ¡ˆåº“æ„å»º (ä¸€æ¬¡æ€§,æ‰¹é‡)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  [ScholarProfileGenerator]                                    â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ LLMæ‰¹é‡ç”Ÿæˆ1000ä¸ªå­¦è€…æ¡£æ¡ˆ                          â”‚
â”‚         â”‚   (å§“åã€æ•™è‚²èƒŒæ™¯ã€è®ºæ–‡åˆ—è¡¨ç­‰)                         â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ [TimelineValidator]                              â”‚
â”‚         â”‚   ç¡¬ç¼–ç è§„åˆ™éªŒè¯æ—¶é—´çº¿ä¸€è‡´æ€§                           â”‚
â”‚         â”‚   (æœ¬ç§‘18å²ã€åšå£«4-6å¹´ã€é¦–ç¯‡è®ºæ–‡æ¯•ä¸šå1å¹´ç­‰)            â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ [VerifiabilityDesign]                            â”‚
â”‚         â”‚   éªŒè¯å®ä½“åˆç†æ€§                                     â”‚
â”‚         â”‚   (çœŸå®æœºæ„ã€çœŸå®venueã€åˆç†å§“åç­‰)                   â”‚
â”‚         â”‚                                                     â”‚
â”‚         â””â”€â†’ ä¿å­˜æ¡£æ¡ˆåº“åˆ°JSONæ–‡ä»¶                               â”‚
â”‚             profiles_db.json (1000ä¸ªæ¡£æ¡ˆ)                     â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ2: é—®é¢˜ç”Ÿæˆ (é‡å¤æ‰§è¡Œ,æ¯æ¬¡ç”ŸæˆNä¸ªé—®é¢˜)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  [QuestionGenerator]                                          â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ åŠ è½½æ¡£æ¡ˆåº“ (profiles_db.json)                     â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ éšæœºé€‰æ‹©æ¨ç†æ¨¡æ¿ (A-G)                            â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ éšæœºé€‰æ‹©çº¦æŸç±»å‹ (3-5ä¸ª)                          â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ [ConstraintValidator]                            â”‚
â”‚         â”‚   æ£€æŸ¥çº¦æŸå…¼å®¹æ€§                                     â”‚
â”‚         â”‚   è‡ªåŠ¨è°ƒæ•´ä¸å…¼å®¹çº¦æŸ                                 â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ ä»æ¡£æ¡ˆåº“é‡‡æ ·å®ä½“                                   â”‚
â”‚         â”‚   (å­¦è€…ã€è®ºæ–‡ç­‰)                                     â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ [UniquenessGuarantee]                            â”‚
â”‚         â”‚   â”œâ”€ æ·»åŠ å…·ä½“çº¦æŸç¼©å°ç­”æ¡ˆç©ºé—´                        â”‚
â”‚         â”‚   â”œâ”€ ç»“æ„åŒ–ç”Ÿæˆæç¤º                                 â”‚
â”‚         â”‚   â”œâ”€ æ˜¾å¼è¦æ±‚å”¯ä¸€æ€§                                 â”‚
â”‚         â”‚   â””â”€ å¤šæ¬¡é‡‡æ ·éªŒè¯ (5æ¬¡,80%ä¸€è‡´æ€§)                    â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ [LLMVerifier]                                     â”‚
â”‚         â”‚   LLMéªŒè¯é—®é¢˜è´¨é‡                                    â”‚
â”‚         â”‚   (æ¸…æ™°åº¦ã€åˆç†æ€§ã€éš¾åº¦ç­‰)                            â”‚
â”‚         â”‚                                                     â”‚
â”‚         â””â”€â†’ è¾“å‡ºQAå¯¹                                           â”‚
â”‚             questions.json                                    â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ3: è´¨é‡è¯„ä¼°ä¸è¿‡æ»¤                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  [QualityEvaluator]                                           â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡                                       â”‚
â”‚         â”‚   â”œâ”€ å¹³å‡çº¦æŸæ•° (ç›®æ ‡: 3-5)                         â”‚
â”‚         â”‚   â”œâ”€ ç­”æ¡ˆå”¯ä¸€æ€§ (ç›®æ ‡: >80%)                        â”‚
â”‚         â”‚   â”œâ”€ å¤šæ ·æ€§ (ç›®æ ‡: >60%)                            â”‚
â”‚         â”‚   â””â”€ ç”ŸæˆæˆåŠŸç‡ (ç›®æ ‡: >70%)                        â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ äººå·¥æŠ½æ ·å®¡æ ¸ (10-20%)                             â”‚
â”‚         â”‚   â”œâ”€ é—®é¢˜æ¸…æ™°åº¦ (1-5åˆ†)                             â”‚
â”‚         â”‚   â”œâ”€ ç­”æ¡ˆåˆç†æ€§ (1-5åˆ†)                             â”‚
â”‚         â”‚   â””â”€ éš¾åº¦è¯„ä¼° (easy/medium/hard)                    â”‚
â”‚         â”‚                                                     â”‚
â”‚         â””â”€â†’ è¿‡æ»¤ä½è´¨é‡é—®é¢˜                                     â”‚
â”‚             final_questions.json                              â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµå›¾

```
[LLM] â”€â”€(ç”Ÿæˆå­¦è€…æ¡£æ¡ˆ)â”€â”€â†’ [ScholarProfile Ã— 1000]
                              â”‚
                              â”œâ”€â†’ [TimelineValidator] â”€â”€(éªŒè¯)â”€â”€â†’ âœ“/âœ—
                              â”‚
                              â””â”€â†’ [profiles_db.json]
                                      â”‚
                                      â”‚ (é‡‡æ ·)
                                      â–¼
[æ¨¡æ¿A-G] + [çº¦æŸ3-5ä¸ª] â”€â”€â†’ [ConstraintValidator] â”€â”€(éªŒè¯å…¼å®¹æ€§)â”€â”€â†’ âœ“/âœ—
                              â”‚
                              â–¼
                    [é‡‡æ ·å­¦è€…+è®ºæ–‡å®ä½“]
                              â”‚
                              â–¼
                    [UniquenessGuarantee]
                              â”‚
                              â”œâ”€â†’ (ç”ŸæˆQA) â”€â”€â†’ [LLM]
                              â”‚
                              â”œâ”€â†’ (å¤šæ¬¡é‡‡æ ·éªŒè¯) â”€â”€â†’ âœ“/âœ—
                              â”‚
                              â””â”€â†’ (question, answer)
                                      â”‚
                                      â–¼
                              [LLMVerifier] â”€â”€(è´¨é‡æ£€æŸ¥)â”€â”€â†’ âœ“/âœ—
                                      â”‚
                                      â–¼
                              [questions.json]
```

---

## ä»£ç å®ç°æ¡†æ¶

### ç›®å½•ç»“æ„

```
browsecomp_v3/
â”œâ”€â”€ synthetic/                      # æ–°å¢: åˆæˆæ•°æ®ç”Ÿæˆæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scholar_profile.py          # å­¦è€…æ¡£æ¡ˆæ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ profile_generator.py        # å­¦è€…æ¡£æ¡ˆç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ timeline_validator.py       # æ—¶é—´çº¿éªŒè¯å™¨
â”‚   â”œâ”€â”€ constraint_validator.py     # çº¦æŸå…¼å®¹æ€§éªŒè¯å™¨
â”‚   â”œâ”€â”€ uniqueness_guarantee.py     # ç­”æ¡ˆå”¯ä¸€æ€§ä¿è¯
â”‚   â”œâ”€â”€ verifiability_design.py     # å¯éªŒè¯æ€§è®¾è®¡
â”‚   â””â”€â”€ llm_verifier.py            # LLMè´¨é‡éªŒè¯å™¨
â”‚
â”œâ”€â”€ constraints/                    # ä¿®æ”¹: çº¦æŸç”Ÿæˆæ¨¡å—
â”‚   â”œâ”€â”€ constraint_generator.py     # ä¿®æ”¹: ä»æ¡£æ¡ˆåº“é‡‡æ ·
â”‚   â””â”€â”€ value_generator.py          # ä¿ç•™: å¤‡ç”¨
â”‚
â”œâ”€â”€ core/                          # ä¿æŒä¸å˜
â”œâ”€â”€ templates/                     # ä¿æŒä¸å˜
â”œâ”€â”€ generator/                     # ä¿æŒä¸å˜
â”œâ”€â”€ validator/                     # ä¿æŒä¸å˜
â””â”€â”€ output/                        # ä¿æŒä¸å˜

data/                              # æ–°å¢: æ•°æ®ç›®å½•
â”œâ”€â”€ profiles_db.json               # è™šæ‹Ÿå­¦è€…æ¡£æ¡ˆåº“
â””â”€â”€ profiles_db_metadata.json      # å…ƒæ•°æ®

scripts/                           # æ–°å¢: è„šæœ¬ç›®å½•
â”œâ”€â”€ generate_profiles.py           # æ­¥éª¤1: ç”Ÿæˆæ¡£æ¡ˆåº“
â”œâ”€â”€ generate_questions.py          # æ­¥éª¤2: ç”Ÿæˆé—®é¢˜
â””â”€â”€ evaluate_quality.py            # æ­¥éª¤3: è´¨é‡è¯„ä¼°
```

### æ ¸å¿ƒä»£ç æ–‡ä»¶

è§ä¸Šæ–‡[æ ¸å¿ƒæœºåˆ¶](#æ ¸å¿ƒæœºåˆ¶)éƒ¨åˆ†çš„è¯¦ç»†ä»£ç å®ç°ã€‚

---

## å®æ–½è®¡åˆ’

### Week 1: æ ¸å¿ƒå¼€å‘

**Day 1-2: æ•°æ®æ¨¡å‹ä¸éªŒè¯å™¨**
- [ ] åˆ›å»º `scholar_profile.py` (ScholarProfile, Paperæ•°æ®ç±»)
- [ ] å®ç° `timeline_validator.py` (ç¡¬ç¼–ç æ—¶é—´çº¿è§„åˆ™)
- [ ] å®ç° `constraint_validator.py` (çº¦æŸå…¼å®¹æ€§æ£€æŸ¥)
- [ ] å•å…ƒæµ‹è¯•: éªŒè¯å™¨é€»è¾‘

**Day 3-4: æ¡£æ¡ˆç”Ÿæˆå™¨ä¸å”¯ä¸€æ€§ä¿è¯**
- [ ] å®ç° `profile_generator.py` (LLMæ‰¹é‡ç”Ÿæˆ1000æ¡£æ¡ˆ)
- [ ] å®ç° `uniqueness_guarantee.py` (4å±‚å”¯ä¸€æ€§æœºåˆ¶)
- [ ] å®ç° `verifiability_design.py` (çœŸå®æœºæ„+è™šæ„å­¦è€…)
- [ ] è„šæœ¬: `scripts/generate_profiles.py`

**Day 5: é›†æˆæµ‹è¯•**
- [ ] ç”Ÿæˆ1000ä¸ªè™šæ‹Ÿå­¦è€…æ¡£æ¡ˆ
- [ ] éªŒè¯æ¡£æ¡ˆæ—¶é—´çº¿ä¸€è‡´æ€§ (ç›®æ ‡: >95%é€šè¿‡)
- [ ] æ£€æŸ¥æ¡£æ¡ˆå®ä½“åˆç†æ€§
- [ ] ä¿å­˜æ¡£æ¡ˆåº“åˆ° `data/profiles_db.json`

### Week 2: é—®é¢˜ç”Ÿæˆä¸è¯„ä¼°

**Day 1-2: ä¿®æ”¹V3çº¦æŸç”Ÿæˆå™¨**
- [ ] ä¿®æ”¹ `constraint_generator.py`
  - ä» `profiles_db.json` åŠ è½½æ¡£æ¡ˆåº“
  - ä»æ¡£æ¡ˆåº“é‡‡æ ·è€Œéä»KGé‡‡æ ·
  - é›†æˆ `ConstraintValidator` æ£€æŸ¥çº¦æŸå…¼å®¹æ€§
- [ ] ä¿®æ”¹ `value_generator.py` (å¯é€‰,ä½œä¸ºå¤‡ç”¨)

**Day 3: LLMéªŒè¯å™¨**
- [ ] å®ç° `llm_verifier.py`
  - éªŒè¯é—®é¢˜æ¸…æ™°åº¦
  - éªŒè¯ç­”æ¡ˆåˆç†æ€§
  - éªŒè¯çº¦æŸæ»¡è¶³åº¦
- [ ] é›†æˆåˆ°é—®é¢˜ç”Ÿæˆæµç¨‹

**Day 4: ç”Ÿæˆ100ä¸ªæµ‹è¯•é—®é¢˜**
- [ ] è„šæœ¬: `scripts/generate_questions.py`
- [ ] ç›®æ ‡: 100ä¸ªé—®é¢˜,3-5çº¦æŸ/é—®é¢˜
- [ ] ä¿å­˜åˆ° `output/questions_synthetic_v1.json`

**Day 5: è´¨é‡è¯„ä¼°**
- [ ] è„šæœ¬: `scripts/evaluate_quality.py`
- [ ] è¯„ä¼°æŒ‡æ ‡:
  - å¹³å‡çº¦æŸæ•°
  - ç­”æ¡ˆå”¯ä¸€æ€§ (å¤šæ¬¡é‡‡æ ·)
  - å¤šæ ·æ€§
  - ç”ŸæˆæˆåŠŸç‡
- [ ] äººå·¥æŠ½æ ·å®¡æ ¸ (10é¢˜)
- [ ] å¯¹æ¯”V3(KG) vs V3-Synthetic

### Week 3: ä¼˜åŒ–ä¸æ‰©å±• (å¯é€‰)

**å¦‚æœWeek 2ç»“æœè¾¾æ ‡** (å¹³å‡çº¦æŸæ•° â‰¥ 3, ç­”æ¡ˆå”¯ä¸€æ€§ â‰¥ 80%):
- [ ] æ‰©å±•åˆ°1000é¢˜ç”Ÿæˆ
- [ ] å®ç°éš¾åº¦è‡ªåŠ¨åˆ†çº§
- [ ] ä¼˜åŒ–ç”Ÿæˆé€Ÿåº¦
- [ ] æ’°å†™å®Œæ•´å®éªŒæŠ¥å‘Š

**å¦‚æœWeek 2ç»“æœä¸è¾¾æ ‡**:
- [ ] åˆ†æå¤±è´¥åŸå› 
- [ ] ä¼˜åŒ–Promptå·¥ç¨‹
- [ ] è°ƒæ•´çº¦æŸå…¼å®¹æ€§è§„åˆ™
- [ ] è¿­ä»£æ”¹è¿›

---

## æˆæœ¬æ•ˆç›Šåˆ†æ

### æˆæœ¬ä¼°ç®—

**é˜¶æ®µ1: ç”Ÿæˆ1000ä¸ªå­¦è€…æ¡£æ¡ˆ**
- LLMè°ƒç”¨æ¬¡æ•°: 1000æ¬¡ (æ¯ä¸ªæ¡£æ¡ˆ1æ¬¡)
- ä¼°è®¡token: 500 tokens/æ¡£æ¡ˆ Ã— 1000 = 500K tokens
- ä½¿ç”¨GPT-4-turbo: $0.01/1K tokens (input) + $0.03/1K tokens (output)
- æˆæœ¬: 500K Ã— $0.01/1K + 250K Ã— $0.03/1K = $5 + $7.5 = **$12.5**

**é˜¶æ®µ2: ç”Ÿæˆ1000ä¸ªé—®é¢˜**
- LLMè°ƒç”¨æ¬¡æ•°: 
  - é—®é¢˜ç”Ÿæˆ: 1000æ¬¡
  - å”¯ä¸€æ€§éªŒè¯: 1000 Ã— 5 = 5000æ¬¡ (æ¯é¢˜5æ¬¡é‡‡æ ·)
  - LLMéªŒè¯å™¨: 1000æ¬¡
  - æ€»è®¡: 7000æ¬¡
- ä¼°è®¡token: 300 tokens/æ¬¡ Ã— 7000 = 2.1M tokens
- æˆæœ¬: 2.1M Ã— $0.01/1K + 1.0M Ã— $0.03/1K = $21 + $30 = **$51**

**å¤±è´¥é‡è¯•æˆæœ¬** (å‡è®¾30%å¤±è´¥ç‡,é‡è¯•2æ¬¡):
- é¢å¤–æˆæœ¬: $51 Ã— 0.3 Ã— 2 = **$30.6**

**æ€»æˆæœ¬**: $12.5 + $51 + $30.6 = **$94.1** (çº¦$100)

### æˆæœ¬ä¼˜åŒ–ç­–ç•¥

1. **ä½¿ç”¨è½»é‡çº§æ¨¡å‹**: æ¡£æ¡ˆç”Ÿæˆå’ŒéªŒè¯å¯ç”¨GPT-3.5-turbo
   - æˆæœ¬é™ä½80%: $100 â†’ **$20**

2. **æ‰¹é‡APIè°ƒç”¨**: OpenAI Batch APIæœ‰50%æŠ˜æ‰£
   - æˆæœ¬é™ä½50%: $100 â†’ **$50**

3. **ç¼“å­˜ä¸­é—´ç»“æœ**: æ¡£æ¡ˆåº“åªç”Ÿæˆä¸€æ¬¡,å¯é‡å¤ä½¿ç”¨
   - åç»­1000é¢˜æˆæœ¬: ä»…$51

4. **æ™ºèƒ½é‡‡æ ·**: åªå¯¹é«˜æ½œåŠ›é—®é¢˜æ·±åº¦éªŒè¯
   - å‡å°‘éªŒè¯æ¬¡æ•°: 5æ¬¡ â†’ 3æ¬¡
   - æˆæœ¬é™ä½30%: $51 â†’ **$35.7**

**ä¼˜åŒ–åæˆæœ¬**: $12.5 + $35.7 = **$48.2** (çº¦$50/1000é¢˜)

### æ•ˆç›Šå¯¹æ¯”

| æŒ‡æ ‡ | V3(KGæ–¹æ¡ˆ) | æ–¹æ¡ˆA(ä¼˜åŒ–å) | æå‡ |
|------|-----------|-------------|------|
| **å•é¢˜æˆæœ¬** | N/A (å—é™) | **$0.05** | - |
| **ç”Ÿæˆé€Ÿåº¦** | 33-57 Q/ç§’ | **100+ Q/ç§’** | +200% |
| **çº¦æŸå¯ç”¨ç‡** | 26.7% (8/30) | **100% (30/30)** | +274% |
| **å¹³å‡çº¦æŸæ•°** | 1.2ä¸ª | **3-5ä¸ª** | +250% |
| **ç”ŸæˆæˆåŠŸç‡** | 14% | **70%+** | +400% |
| **å¼€å‘æ—¶é—´** | å·²å®Œæˆ | **2å‘¨** | - |

### ROIè®¡ç®—

**æŠ•èµ„**:
- å¼€å‘æ—¶é—´: 2å‘¨ Ã— $1000/å‘¨ = $2000 (äººåŠ›æˆæœ¬)
- LLMæˆæœ¬: $50/1000é¢˜
- **æ€»æŠ•èµ„**: $2050

**å›æŠ¥**:
- 1000é¢˜å¤æ‚é—®é¢˜ (3-5çº¦æŸ)
- 100%çº¦æŸå¯ç”¨ (vs 27%)
- å¯æ‰©å±•åˆ°10K+é¢˜ (è¾¹é™…æˆæœ¬ä»…$50/1000é¢˜)
- éªŒè¯åˆæˆæ•°æ®æ–¹æ¡ˆå¯è¡Œæ€§ â†’ å¯è½¬å‘æ–¹å‘C (BrowseComp benchmark)

**ROI**: å¦‚æœæˆåŠŸ,æŠ•èµ„å›æŠ¥ç‡ = âˆ (æ‰“å¼€äº†æ–°çš„ç ”ç©¶æ–¹å‘)

---

## é™„å½•

### A. æ—¶é—´çº¿è§„åˆ™å®Œæ•´æ¸…å•

```python
TIMELINE_RULES = {
    "bachelor_age": {
        "rule": "bachelor_year - birth_year >= 18",
        "description": "æœ¬ç§‘æ¯•ä¸šå¹´é¾„ä¸å°äº18å²",
        "priority": 1  # æœ€é«˜ä¼˜å…ˆçº§
    },
    "phd_duration": {
        "rule": "phd_year - bachelor_year >= 4",
        "description": "åšå£«å­¦ä¹ æ—¶é—´ä¸å°‘äº4å¹´",
        "priority": 2
    },
    "first_paper_after_phd": {
        "rule": "first_paper_year >= phd_year + 1",
        "description": "é¦–ç¯‡è®ºæ–‡ä¸æ—©äºåšå£«æ¯•ä¸šå1å¹´",
        "priority": 3
    },
    "join_after_phd": {
        "rule": "join_year >= phd_year",
        "description": "å…¥èŒæ—¶é—´ä¸æ—©äºåšå£«æ¯•ä¸š",
        "priority": 3
    },
    "paper_before_current_year": {
        "rule": "paper_year <= 2024",
        "description": "è®ºæ–‡å¹´ä»½ä¸æ™šäºå½“å‰å¹´ä»½",
        "priority": 1
    },
    "reasonable_citation": {
        "rule": "total_citations / paper_count <= 1000",
        "description": "å¹³å‡å¼•ç”¨æ•°ä¸è¶…è¿‡1000",
        "priority": 4
    },
    "coauthor_after_enrollment": {
        "rule": "coauthor_year >= phd_year - 4",
        "description": "åˆä½œæ—¶é—´ä¸æ—©äºåšå£«å…¥å­¦",
        "priority": 3
    },
}
```

### B. çº¦æŸå…¼å®¹æ€§çŸ©é˜µ

| çº¦æŸ1 | çº¦æŸ2 | å…¼å®¹è§„åˆ™ | ä¼˜å…ˆçº§ |
|------|------|---------|-------|
| birth_year | bachelor_year | bachelor â‰¥ birth + 18 | é«˜ |
| bachelor_year | phd_year | phd â‰¥ bachelor + 4 | é«˜ |
| phd_year | first_paper_year | paper â‰¥ phd + 1 | é«˜ |
| phd_year | join_year | join â‰¥ phd | ä¸­ |
| phd_year | coauthor_year | coauthor â‰¥ phd - 4 | ä¸­ |
| paper_year | citation_count | citationsåˆç†èŒƒå›´ | ä½ |

### C. LLM Promptæ¨¡æ¿ç¤ºä¾‹

```
ç”Ÿæˆå­¦è€…æ¡£æ¡ˆ:
"""
Generate a realistic but fictional academic scholar profile in JSON format:

Requirements:
1. Name: Plausible Chinese/English name (avoid common names like "å¼ ä¼Ÿ")
2. Birth year: 1985-1995
3. Bachelor graduation at age 22 (birth_year + 22)
4. PhD duration: 4-6 years after bachelor
5. First paper: 1-5 years after PhD graduation
6. Institutions: Real top universities only (MIT, Stanford, Tsinghua, etc.)
7. Papers: 3-8 papers total
8. All dates must be logically consistent

Example output:
{
    "name": "ææ˜è½©",
    "birth_year": 1990,
    "bachelor_uni": "æ¸…åå¤§å­¦",
    "bachelor_year": 2012,
    "phd_uni": "MIT",
    "phd_year": 2017,
    "papers": [...]
}
"""

ç”Ÿæˆé—®é¢˜:
"""
Generate a question-answer pair based on:
Template: Paper-Author-Institution chain
Constraints: publication_year=2020, author_name="ææ˜è½©"

Output JSON:
{
    "question": "2020å¹´å‘è¡¨çš„è®ºæ–‡ä¸­,ä½œè€…ææ˜è½©(æœ¬ç§‘æ¯•ä¸šäºæ¸…åå¤§å­¦,åšå£«æ¯•ä¸šäºMIT)çš„è®ºæ–‡æ ‡é¢˜æ˜¯ä»€ä¹ˆ?",
    "answer": "Attention Mechanisms for Multi-hop Reasoning"
}

CRITICAL: The answer must be uniquely determined by the constraints.
"""
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2026-02-04  
**ä¸‹æ¬¡æ›´æ–°**: å®æ–½Week 1å®Œæˆå
